{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Author: Umang Srivastav"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here ResNet-50 is trained on CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beS8vGWbfZ8C",
        "outputId": "fb560fc4-2ace-4349-c926-3c817b768490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 103017669.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Test Accuracy: 19.34%\n",
            "Epoch [2/100], Test Accuracy: 28.57%\n",
            "Epoch [3/100], Test Accuracy: 32.79%\n",
            "Epoch [4/100], Test Accuracy: 38.72%\n",
            "Epoch [5/100], Test Accuracy: 42.02%\n",
            "Epoch [6/100], Test Accuracy: 43.44%\n",
            "Epoch [7/100], Test Accuracy: 45.46%\n",
            "Epoch [8/100], Test Accuracy: 46.05%\n",
            "Epoch [9/100], Test Accuracy: 48.43%\n",
            "Epoch [10/100], Test Accuracy: 50.62%\n",
            "Epoch [11/100], Test Accuracy: 47.17%\n",
            "Epoch [12/100], Test Accuracy: 52.64%\n",
            "Epoch [13/100], Test Accuracy: 54.08%\n",
            "Epoch [14/100], Test Accuracy: 53.84%\n",
            "Epoch [15/100], Test Accuracy: 55.77%\n",
            "Epoch [16/100], Test Accuracy: 56.77%\n",
            "Epoch [17/100], Test Accuracy: 57.34%\n",
            "Epoch [18/100], Test Accuracy: 58.58%\n",
            "Epoch [19/100], Test Accuracy: 59.40%\n",
            "Epoch [20/100], Test Accuracy: 61.93%\n",
            "Epoch [21/100], Test Accuracy: 62.28%\n",
            "Epoch [22/100], Test Accuracy: 58.75%\n",
            "Epoch [23/100], Test Accuracy: 63.21%\n",
            "Epoch [24/100], Test Accuracy: 65.11%\n",
            "Epoch [25/100], Test Accuracy: 66.16%\n",
            "Epoch [26/100], Test Accuracy: 64.86%\n",
            "Epoch [27/100], Test Accuracy: 66.84%\n",
            "Epoch [28/100], Test Accuracy: 68.45%\n",
            "Epoch [29/100], Test Accuracy: 69.86%\n",
            "Epoch [30/100], Test Accuracy: 70.04%\n",
            "Epoch [31/100], Test Accuracy: 67.41%\n",
            "Epoch [32/100], Test Accuracy: 71.67%\n",
            "Epoch [33/100], Test Accuracy: 72.48%\n",
            "Epoch [34/100], Test Accuracy: 72.86%\n",
            "Epoch [35/100], Test Accuracy: 72.18%\n",
            "Epoch [36/100], Test Accuracy: 73.65%\n",
            "Epoch [37/100], Test Accuracy: 73.15%\n",
            "Epoch [38/100], Test Accuracy: 74.55%\n",
            "Epoch [39/100], Test Accuracy: 74.92%\n",
            "Epoch [40/100], Test Accuracy: 74.45%\n",
            "Epoch [41/100], Test Accuracy: 74.83%\n",
            "Epoch [42/100], Test Accuracy: 75.60%\n",
            "Epoch [43/100], Test Accuracy: 76.16%\n",
            "Epoch [44/100], Test Accuracy: 75.93%\n",
            "Epoch [45/100], Test Accuracy: 75.65%\n",
            "Epoch [46/100], Test Accuracy: 75.73%\n",
            "Epoch [47/100], Test Accuracy: 76.44%\n",
            "Epoch [48/100], Test Accuracy: 76.65%\n",
            "Epoch [49/100], Test Accuracy: 76.33%\n",
            "Epoch [50/100], Test Accuracy: 75.91%\n",
            "Epoch [51/100], Test Accuracy: 77.29%\n",
            "Epoch [52/100], Test Accuracy: 77.01%\n",
            "Epoch [53/100], Test Accuracy: 78.91%\n",
            "Epoch [54/100], Test Accuracy: 78.03%\n",
            "Epoch [55/100], Test Accuracy: 76.63%\n",
            "Epoch [56/100], Test Accuracy: 78.46%\n",
            "Epoch [57/100], Test Accuracy: 78.42%\n",
            "Epoch [58/100], Test Accuracy: 78.91%\n",
            "Epoch [59/100], Test Accuracy: 78.02%\n",
            "Epoch [60/100], Test Accuracy: 78.53%\n",
            "Epoch [61/100], Test Accuracy: 79.51%\n",
            "Epoch [62/100], Test Accuracy: 79.17%\n",
            "Epoch [63/100], Test Accuracy: 79.78%\n",
            "Epoch [64/100], Test Accuracy: 79.05%\n",
            "Epoch [65/100], Test Accuracy: 80.02%\n",
            "Epoch [66/100], Test Accuracy: 79.79%\n",
            "Epoch [67/100], Test Accuracy: 78.92%\n",
            "Epoch [68/100], Test Accuracy: 79.41%\n",
            "Epoch [69/100], Test Accuracy: 79.61%\n",
            "Epoch [70/100], Test Accuracy: 80.43%\n",
            "Epoch [71/100], Test Accuracy: 79.77%\n",
            "Epoch [72/100], Test Accuracy: 80.52%\n",
            "Epoch [73/100], Test Accuracy: 80.84%\n",
            "Epoch [74/100], Test Accuracy: 79.23%\n",
            "Epoch [75/100], Test Accuracy: 80.97%\n",
            "Epoch [76/100], Test Accuracy: 81.04%\n",
            "Epoch [77/100], Test Accuracy: 80.42%\n",
            "Epoch [78/100], Test Accuracy: 80.25%\n",
            "Epoch [79/100], Test Accuracy: 80.22%\n",
            "Epoch [80/100], Test Accuracy: 80.70%\n",
            "Epoch [81/100], Test Accuracy: 80.79%\n",
            "Epoch [82/100], Test Accuracy: 80.81%\n",
            "Epoch [83/100], Test Accuracy: 80.51%\n",
            "Epoch [84/100], Test Accuracy: 80.07%\n",
            "Epoch [85/100], Test Accuracy: 81.49%\n",
            "Epoch [86/100], Test Accuracy: 81.00%\n",
            "Epoch [87/100], Test Accuracy: 80.60%\n",
            "Epoch [88/100], Test Accuracy: 81.91%\n",
            "Epoch [89/100], Test Accuracy: 81.38%\n",
            "Epoch [90/100], Test Accuracy: 81.49%\n",
            "Epoch [91/100], Test Accuracy: 80.72%\n",
            "Epoch [92/100], Test Accuracy: 81.43%\n",
            "Epoch [93/100], Test Accuracy: 81.84%\n",
            "Epoch [94/100], Test Accuracy: 81.46%\n",
            "Epoch [95/100], Test Accuracy: 81.22%\n",
            "Epoch [96/100], Test Accuracy: 81.23%\n",
            "Epoch [97/100], Test Accuracy: 80.87%\n",
            "Epoch [98/100], Test Accuracy: 81.17%\n",
            "Epoch [99/100], Test Accuracy: 80.82%\n",
            "Epoch [100/100], Test Accuracy: 81.78%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "model = models.resnet50(pretrained=False, num_classes=100)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for images, labels in train_loader:\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew97DnLjvG8U"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model50.pt') #Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEDSl-V5dUmN",
        "outputId": "328452e0-5fd6-4d1b-8b38-629331e1ea1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "model=models.resnet50(pretrained=False, num_classes=100)\n",
        "model.load_state_dict(torch.load('model50.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5Dmm8Gg6F0j"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I have taken a first few layers of trained model and fine tuned with adding 2 extra FC layers and trained on CIFAR100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVUwsjeEcPvS",
        "outputId": "05ab98e5-233c-49f4-bd0f-206bd481b965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight is not trainable\n",
            "bn1.weight is not trainable\n",
            "bn1.bias is not trainable\n",
            "layer1.0.conv1.weight is not trainable\n",
            "layer1.0.bn1.weight is not trainable\n",
            "layer1.0.bn1.bias is not trainable\n",
            "layer1.0.conv2.weight is not trainable\n",
            "layer1.0.bn2.weight is not trainable\n",
            "layer1.0.bn2.bias is not trainable\n",
            "layer1.0.conv3.weight is not trainable\n",
            "layer1.0.bn3.weight is not trainable\n",
            "layer1.0.bn3.bias is not trainable\n",
            "layer1.0.downsample.0.weight is not trainable\n",
            "layer1.0.downsample.1.weight is not trainable\n",
            "layer1.0.downsample.1.bias is not trainable\n",
            "layer1.1.conv1.weight is not trainable\n",
            "layer1.1.bn1.weight is not trainable\n",
            "layer1.1.bn1.bias is not trainable\n",
            "layer1.1.conv2.weight is not trainable\n",
            "layer1.1.bn2.weight is not trainable\n",
            "layer1.1.bn2.bias is not trainable\n",
            "layer1.1.conv3.weight is not trainable\n",
            "layer1.1.bn3.weight is not trainable\n",
            "layer1.1.bn3.bias is not trainable\n",
            "layer1.2.conv1.weight is not trainable\n",
            "layer1.2.bn1.weight is not trainable\n",
            "layer1.2.bn1.bias is not trainable\n",
            "layer1.2.conv2.weight is not trainable\n",
            "layer1.2.bn2.weight is not trainable\n",
            "layer1.2.bn2.bias is not trainable\n",
            "layer1.2.conv3.weight is not trainable\n",
            "layer1.2.bn3.weight is not trainable\n",
            "layer1.2.bn3.bias is not trainable\n",
            "layer2.0.conv1.weight is not trainable\n",
            "layer2.0.bn1.weight is not trainable\n",
            "layer2.0.bn1.bias is not trainable\n",
            "layer2.0.conv2.weight is not trainable\n",
            "layer2.0.bn2.weight is not trainable\n",
            "layer2.0.bn2.bias is not trainable\n",
            "layer2.0.conv3.weight is not trainable\n",
            "layer2.0.bn3.weight is not trainable\n",
            "layer2.0.bn3.bias is not trainable\n",
            "layer2.0.downsample.0.weight is not trainable\n",
            "layer2.0.downsample.1.weight is not trainable\n",
            "layer2.0.downsample.1.bias is not trainable\n",
            "layer2.1.conv1.weight is not trainable\n",
            "layer2.1.bn1.weight is not trainable\n",
            "layer2.1.bn1.bias is not trainable\n",
            "layer2.1.conv2.weight is not trainable\n",
            "layer2.1.bn2.weight is not trainable\n",
            "layer2.1.bn2.bias is not trainable\n",
            "layer2.1.conv3.weight is not trainable\n",
            "layer2.1.bn3.weight is not trainable\n",
            "layer2.1.bn3.bias is not trainable\n",
            "layer2.2.conv1.weight is not trainable\n",
            "layer2.2.bn1.weight is not trainable\n",
            "layer2.2.bn1.bias is not trainable\n",
            "layer2.2.conv2.weight is not trainable\n",
            "layer2.2.bn2.weight is not trainable\n",
            "layer2.2.bn2.bias is not trainable\n",
            "layer2.2.conv3.weight is not trainable\n",
            "layer2.2.bn3.weight is not trainable\n",
            "layer2.2.bn3.bias is not trainable\n",
            "layer2.3.conv1.weight is not trainable\n",
            "layer2.3.bn1.weight is not trainable\n",
            "layer2.3.bn1.bias is not trainable\n",
            "layer2.3.conv2.weight is not trainable\n",
            "layer2.3.bn2.weight is not trainable\n",
            "layer2.3.bn2.bias is not trainable\n",
            "layer2.3.conv3.weight is not trainable\n",
            "layer2.3.bn3.weight is not trainable\n",
            "layer2.3.bn3.bias is not trainable\n",
            "fc.weight is trainable\n",
            "fc.bias is trainable\n",
            "fc2.weight is trainable\n",
            "fc2.bias is trainable\n",
            "fc3.weight is trainable\n",
            "fc3.bias is trainable\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/100], Test Accuracy: 7.27%\n",
            "Epoch [2/100], Test Accuracy: 7.75%\n",
            "Epoch [3/100], Test Accuracy: 11.17%\n",
            "Epoch [4/100], Test Accuracy: 14.98%\n",
            "Epoch [5/100], Test Accuracy: 16.76%\n",
            "Epoch [6/100], Test Accuracy: 19.45%\n",
            "Epoch [7/100], Test Accuracy: 20.33%\n",
            "Epoch [8/100], Test Accuracy: 21.86%\n",
            "Epoch [9/100], Test Accuracy: 22.81%\n",
            "Epoch [10/100], Test Accuracy: 24.39%\n",
            "Epoch [11/100], Test Accuracy: 25.11%\n",
            "Epoch [12/100], Test Accuracy: 25.79%\n",
            "Epoch [13/100], Test Accuracy: 26.57%\n",
            "Epoch [14/100], Test Accuracy: 27.48%\n",
            "Epoch [15/100], Test Accuracy: 27.79%\n",
            "Epoch [16/100], Test Accuracy: 28.73%\n",
            "Epoch [17/100], Test Accuracy: 29.50%\n",
            "Epoch [18/100], Test Accuracy: 29.29%\n",
            "Epoch [19/100], Test Accuracy: 30.02%\n",
            "Epoch [20/100], Test Accuracy: 30.97%\n",
            "Epoch [21/100], Test Accuracy: 30.97%\n",
            "Epoch [22/100], Test Accuracy: 31.33%\n",
            "Epoch [23/100], Test Accuracy: 31.58%\n",
            "Epoch [24/100], Test Accuracy: 31.97%\n",
            "Epoch [25/100], Test Accuracy: 32.17%\n",
            "Epoch [26/100], Test Accuracy: 32.40%\n",
            "Epoch [27/100], Test Accuracy: 32.86%\n",
            "Epoch [28/100], Test Accuracy: 33.01%\n",
            "Epoch [29/100], Test Accuracy: 33.24%\n",
            "Epoch [30/100], Test Accuracy: 33.56%\n",
            "Epoch [31/100], Test Accuracy: 33.60%\n",
            "Epoch [32/100], Test Accuracy: 34.07%\n",
            "Epoch [33/100], Test Accuracy: 34.56%\n",
            "Epoch [34/100], Test Accuracy: 34.03%\n",
            "Epoch [35/100], Test Accuracy: 34.98%\n",
            "Epoch [36/100], Test Accuracy: 35.35%\n",
            "Epoch [37/100], Test Accuracy: 35.14%\n",
            "Epoch [38/100], Test Accuracy: 35.31%\n",
            "Epoch [39/100], Test Accuracy: 34.94%\n",
            "Epoch [40/100], Test Accuracy: 35.80%\n",
            "Epoch [41/100], Test Accuracy: 35.90%\n",
            "Epoch [42/100], Test Accuracy: 36.06%\n",
            "Epoch [43/100], Test Accuracy: 36.10%\n",
            "Epoch [44/100], Test Accuracy: 36.69%\n",
            "Epoch [45/100], Test Accuracy: 36.30%\n",
            "Epoch [46/100], Test Accuracy: 36.73%\n",
            "Epoch [47/100], Test Accuracy: 36.77%\n",
            "Epoch [48/100], Test Accuracy: 36.50%\n",
            "Epoch [49/100], Test Accuracy: 37.24%\n",
            "Epoch [50/100], Test Accuracy: 37.09%\n",
            "Epoch [51/100], Test Accuracy: 37.34%\n",
            "Epoch [52/100], Test Accuracy: 37.27%\n",
            "Epoch [53/100], Test Accuracy: 37.56%\n",
            "Epoch [54/100], Test Accuracy: 37.40%\n",
            "Epoch [55/100], Test Accuracy: 37.65%\n",
            "Epoch [56/100], Test Accuracy: 37.50%\n",
            "Epoch [57/100], Test Accuracy: 38.28%\n",
            "Epoch [58/100], Test Accuracy: 37.66%\n",
            "Epoch [59/100], Test Accuracy: 38.35%\n",
            "Epoch [60/100], Test Accuracy: 38.06%\n",
            "Epoch [61/100], Test Accuracy: 38.07%\n",
            "Epoch [62/100], Test Accuracy: 38.31%\n",
            "Epoch [63/100], Test Accuracy: 38.76%\n",
            "Epoch [64/100], Test Accuracy: 37.98%\n",
            "Epoch [65/100], Test Accuracy: 38.31%\n",
            "Epoch [66/100], Test Accuracy: 38.88%\n",
            "Epoch [67/100], Test Accuracy: 38.96%\n",
            "Epoch [68/100], Test Accuracy: 38.35%\n",
            "Epoch [69/100], Test Accuracy: 38.75%\n",
            "Epoch [70/100], Test Accuracy: 38.72%\n",
            "Epoch [71/100], Test Accuracy: 38.74%\n",
            "Epoch [72/100], Test Accuracy: 38.53%\n",
            "Epoch [73/100], Test Accuracy: 38.92%\n",
            "Epoch [74/100], Test Accuracy: 39.12%\n",
            "Epoch [75/100], Test Accuracy: 38.87%\n",
            "Epoch [76/100], Test Accuracy: 39.63%\n",
            "Epoch [77/100], Test Accuracy: 38.95%\n",
            "Epoch [78/100], Test Accuracy: 39.53%\n",
            "Epoch [79/100], Test Accuracy: 39.42%\n",
            "Epoch [80/100], Test Accuracy: 40.31%\n",
            "Epoch [81/100], Test Accuracy: 38.75%\n",
            "Epoch [82/100], Test Accuracy: 40.03%\n",
            "Epoch [83/100], Test Accuracy: 39.92%\n",
            "Epoch [84/100], Test Accuracy: 39.49%\n",
            "Epoch [85/100], Test Accuracy: 39.21%\n",
            "Epoch [86/100], Test Accuracy: 39.36%\n",
            "Epoch [87/100], Test Accuracy: 39.42%\n",
            "Epoch [88/100], Test Accuracy: 39.71%\n",
            "Epoch [89/100], Test Accuracy: 39.63%\n",
            "Epoch [90/100], Test Accuracy: 39.51%\n",
            "Epoch [91/100], Test Accuracy: 39.12%\n",
            "Epoch [92/100], Test Accuracy: 40.54%\n",
            "Epoch [93/100], Test Accuracy: 39.50%\n",
            "Epoch [94/100], Test Accuracy: 39.88%\n",
            "Epoch [95/100], Test Accuracy: 39.27%\n",
            "Epoch [96/100], Test Accuracy: 39.90%\n",
            "Epoch [97/100], Test Accuracy: 40.70%\n",
            "Epoch [98/100], Test Accuracy: 39.88%\n",
            "Epoch [99/100], Test Accuracy: 40.60%\n",
            "Epoch [100/100], Test Accuracy: 40.36%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "class ModifiedResNet50(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        \n",
        "        resnet=model#.resnet\n",
        "        self.conv1=resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        # del self.layer2[3]\n",
        "        # del self.layer2[2].conv2\n",
        "        # del self.layer2[2].conv3\n",
        "        # del self.layer2[2].bn2\n",
        "        # del self.layer2[2].bn3\n",
        "        self.avgpool = resnet.avgpool\n",
        "        self.fc=torch.nn.Linear(in_features=512, out_features=100, bias=True)\n",
        "\n",
        "        self.fc2=torch.nn.Linear(in_features=100, out_features=500, bias=True)\n",
        "        self.fc3=torch.nn.Linear(in_features=500, out_features=100, bias=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "model = ModifiedResNet50(model) \n",
        "model=model.to(device)\n",
        "# print(model)\n",
        "import torchvision\n",
        "for name, param in model.named_parameters():\n",
        "    if name.startswith('fc'):\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, \"is trainable\")\n",
        "    else:\n",
        "        print(name, \"is not trainable\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762])\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "validset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in validloader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'Modmodel50-18.pt')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I have taken a first few layers of trained model and fine tuned with adding an FC layers and trained on CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmA_pMGw2-vD",
        "outputId": "93e17ab1-f56d-4e0c-f6b9-764017262bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight is not trainable\n",
            "bn1.weight is not trainable\n",
            "bn1.bias is not trainable\n",
            "layer1.0.conv1.weight is not trainable\n",
            "layer1.0.bn1.weight is not trainable\n",
            "layer1.0.bn1.bias is not trainable\n",
            "layer1.0.conv2.weight is not trainable\n",
            "layer1.0.bn2.weight is not trainable\n",
            "layer1.0.bn2.bias is not trainable\n",
            "layer1.0.conv3.weight is not trainable\n",
            "layer1.0.bn3.weight is not trainable\n",
            "layer1.0.bn3.bias is not trainable\n",
            "layer1.0.downsample.0.weight is not trainable\n",
            "layer1.0.downsample.1.weight is not trainable\n",
            "layer1.0.downsample.1.bias is not trainable\n",
            "layer1.1.conv1.weight is not trainable\n",
            "layer1.1.bn1.weight is not trainable\n",
            "layer1.1.bn1.bias is not trainable\n",
            "layer1.1.conv2.weight is not trainable\n",
            "layer1.1.bn2.weight is not trainable\n",
            "layer1.1.bn2.bias is not trainable\n",
            "layer1.1.conv3.weight is not trainable\n",
            "layer1.1.bn3.weight is not trainable\n",
            "layer1.1.bn3.bias is not trainable\n",
            "layer1.2.conv1.weight is not trainable\n",
            "layer1.2.bn1.weight is not trainable\n",
            "layer1.2.bn1.bias is not trainable\n",
            "layer1.2.conv2.weight is not trainable\n",
            "layer1.2.bn2.weight is not trainable\n",
            "layer1.2.bn2.bias is not trainable\n",
            "layer1.2.conv3.weight is not trainable\n",
            "layer1.2.bn3.weight is not trainable\n",
            "layer1.2.bn3.bias is not trainable\n",
            "layer2.0.conv1.weight is not trainable\n",
            "layer2.0.bn1.weight is not trainable\n",
            "layer2.0.bn1.bias is not trainable\n",
            "layer2.0.conv2.weight is not trainable\n",
            "layer2.0.bn2.weight is not trainable\n",
            "layer2.0.bn2.bias is not trainable\n",
            "layer2.0.conv3.weight is not trainable\n",
            "layer2.0.bn3.weight is not trainable\n",
            "layer2.0.bn3.bias is not trainable\n",
            "layer2.0.downsample.0.weight is not trainable\n",
            "layer2.0.downsample.1.weight is not trainable\n",
            "layer2.0.downsample.1.bias is not trainable\n",
            "layer2.1.conv1.weight is not trainable\n",
            "layer2.1.bn1.weight is not trainable\n",
            "layer2.1.bn1.bias is not trainable\n",
            "layer2.1.conv2.weight is not trainable\n",
            "layer2.1.bn2.weight is not trainable\n",
            "layer2.1.bn2.bias is not trainable\n",
            "layer2.1.conv3.weight is not trainable\n",
            "layer2.1.bn3.weight is not trainable\n",
            "layer2.1.bn3.bias is not trainable\n",
            "layer2.2.conv1.weight is not trainable\n",
            "layer2.2.bn1.weight is not trainable\n",
            "layer2.2.bn1.bias is not trainable\n",
            "layer2.2.conv2.weight is not trainable\n",
            "layer2.2.bn2.weight is not trainable\n",
            "layer2.2.bn2.bias is not trainable\n",
            "layer2.2.conv3.weight is not trainable\n",
            "layer2.2.bn3.weight is not trainable\n",
            "layer2.2.bn3.bias is not trainable\n",
            "layer2.3.conv1.weight is not trainable\n",
            "layer2.3.bn1.weight is not trainable\n",
            "layer2.3.bn1.bias is not trainable\n",
            "layer2.3.conv2.weight is not trainable\n",
            "layer2.3.bn2.weight is not trainable\n",
            "layer2.3.bn2.bias is not trainable\n",
            "layer2.3.conv3.weight is not trainable\n",
            "layer2.3.bn3.weight is not trainable\n",
            "layer2.3.bn3.bias is not trainable\n",
            "fc.weight is trainable\n",
            "fc.bias is trainable\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/100], Test Accuracy: 67.31%\n",
            "Epoch [2/100], Test Accuracy: 69.96%\n",
            "Epoch [3/100], Test Accuracy: 71.90%\n",
            "Epoch [4/100], Test Accuracy: 72.65%\n",
            "Epoch [5/100], Test Accuracy: 73.15%\n",
            "Epoch [6/100], Test Accuracy: 73.79%\n",
            "Epoch [7/100], Test Accuracy: 73.50%\n",
            "Epoch [8/100], Test Accuracy: 74.31%\n",
            "Epoch [9/100], Test Accuracy: 74.11%\n",
            "Epoch [10/100], Test Accuracy: 74.67%\n",
            "Epoch [11/100], Test Accuracy: 74.93%\n",
            "Epoch [12/100], Test Accuracy: 75.47%\n",
            "Epoch [13/100], Test Accuracy: 75.84%\n",
            "Epoch [14/100], Test Accuracy: 76.10%\n",
            "Epoch [15/100], Test Accuracy: 75.49%\n",
            "Epoch [16/100], Test Accuracy: 76.26%\n",
            "Epoch [17/100], Test Accuracy: 76.20%\n",
            "Epoch [18/100], Test Accuracy: 76.39%\n",
            "Epoch [19/100], Test Accuracy: 76.73%\n",
            "Epoch [20/100], Test Accuracy: 76.96%\n",
            "Epoch [21/100], Test Accuracy: 77.06%\n",
            "Epoch [22/100], Test Accuracy: 76.94%\n",
            "Epoch [23/100], Test Accuracy: 77.16%\n",
            "Epoch [24/100], Test Accuracy: 77.09%\n",
            "Epoch [25/100], Test Accuracy: 77.15%\n",
            "Epoch [26/100], Test Accuracy: 77.13%\n",
            "Epoch [27/100], Test Accuracy: 77.52%\n",
            "Epoch [28/100], Test Accuracy: 77.47%\n",
            "Epoch [29/100], Test Accuracy: 77.43%\n",
            "Epoch [30/100], Test Accuracy: 77.01%\n",
            "Epoch [31/100], Test Accuracy: 76.70%\n",
            "Epoch [32/100], Test Accuracy: 77.15%\n",
            "Epoch [33/100], Test Accuracy: 76.57%\n",
            "Epoch [34/100], Test Accuracy: 77.75%\n",
            "Epoch [35/100], Test Accuracy: 77.34%\n",
            "Epoch [36/100], Test Accuracy: 77.45%\n",
            "Epoch [37/100], Test Accuracy: 77.75%\n",
            "Epoch [38/100], Test Accuracy: 77.63%\n",
            "Epoch [39/100], Test Accuracy: 77.92%\n",
            "Epoch [40/100], Test Accuracy: 78.33%\n",
            "Epoch [41/100], Test Accuracy: 78.15%\n",
            "Epoch [42/100], Test Accuracy: 77.86%\n",
            "Epoch [43/100], Test Accuracy: 77.70%\n",
            "Epoch [44/100], Test Accuracy: 77.67%\n",
            "Epoch [45/100], Test Accuracy: 77.78%\n",
            "Epoch [46/100], Test Accuracy: 77.39%\n",
            "Epoch [47/100], Test Accuracy: 77.83%\n",
            "Epoch [48/100], Test Accuracy: 77.95%\n",
            "Epoch [49/100], Test Accuracy: 78.22%\n",
            "Epoch [50/100], Test Accuracy: 77.58%\n",
            "Epoch [51/100], Test Accuracy: 78.05%\n",
            "Epoch [52/100], Test Accuracy: 77.83%\n",
            "Epoch [53/100], Test Accuracy: 78.39%\n",
            "Epoch [54/100], Test Accuracy: 78.22%\n",
            "Epoch [55/100], Test Accuracy: 78.33%\n",
            "Epoch [56/100], Test Accuracy: 78.06%\n",
            "Epoch [57/100], Test Accuracy: 77.95%\n",
            "Epoch [58/100], Test Accuracy: 78.13%\n",
            "Epoch [59/100], Test Accuracy: 78.03%\n",
            "Epoch [60/100], Test Accuracy: 77.98%\n",
            "Epoch [61/100], Test Accuracy: 78.34%\n",
            "Epoch [62/100], Test Accuracy: 77.88%\n",
            "Epoch [63/100], Test Accuracy: 78.68%\n",
            "Epoch [64/100], Test Accuracy: 77.88%\n",
            "Epoch [65/100], Test Accuracy: 78.35%\n",
            "Epoch [66/100], Test Accuracy: 78.56%\n",
            "Epoch [67/100], Test Accuracy: 78.38%\n",
            "Epoch [68/100], Test Accuracy: 78.46%\n",
            "Epoch [69/100], Test Accuracy: 78.09%\n",
            "Epoch [70/100], Test Accuracy: 78.00%\n",
            "Epoch [71/100], Test Accuracy: 78.67%\n",
            "Epoch [72/100], Test Accuracy: 78.54%\n",
            "Epoch [73/100], Test Accuracy: 78.37%\n",
            "Epoch [74/100], Test Accuracy: 78.78%\n",
            "Epoch [75/100], Test Accuracy: 78.31%\n",
            "Epoch [76/100], Test Accuracy: 78.83%\n",
            "Epoch [77/100], Test Accuracy: 78.53%\n",
            "Epoch [78/100], Test Accuracy: 78.42%\n",
            "Epoch [79/100], Test Accuracy: 78.53%\n",
            "Epoch [80/100], Test Accuracy: 78.82%\n",
            "Epoch [81/100], Test Accuracy: 78.36%\n",
            "Epoch [82/100], Test Accuracy: 78.09%\n",
            "Epoch [83/100], Test Accuracy: 78.64%\n",
            "Epoch [84/100], Test Accuracy: 78.60%\n",
            "Epoch [85/100], Test Accuracy: 79.08%\n",
            "Epoch [86/100], Test Accuracy: 78.84%\n",
            "Epoch [87/100], Test Accuracy: 78.58%\n",
            "Epoch [88/100], Test Accuracy: 78.92%\n",
            "Epoch [89/100], Test Accuracy: 78.69%\n",
            "Epoch [90/100], Test Accuracy: 78.33%\n",
            "Epoch [91/100], Test Accuracy: 78.27%\n",
            "Epoch [92/100], Test Accuracy: 78.76%\n",
            "Epoch [93/100], Test Accuracy: 78.43%\n",
            "Epoch [94/100], Test Accuracy: 79.13%\n",
            "Epoch [95/100], Test Accuracy: 78.75%\n",
            "Epoch [96/100], Test Accuracy: 78.81%\n",
            "Epoch [97/100], Test Accuracy: 79.08%\n",
            "Epoch [98/100], Test Accuracy: 78.73%\n",
            "Epoch [99/100], Test Accuracy: 79.08%\n",
            "Epoch [100/100], Test Accuracy: 78.69%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "class ModifiedResNet50(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        \n",
        "        resnet=model#.resnet\n",
        "        self.conv1=resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        # del self.layer2[3]\n",
        "        # del self.layer2[2].conv2\n",
        "        # del self.layer2[2].conv3\n",
        "        # del self.layer2[2].bn2\n",
        "        # del self.layer2[2].bn3\n",
        "        self.avgpool = resnet.avgpool\n",
        "        self.fc=torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "\n",
        "        # self.fc2=torch.nn.Linear(in_features=100, out_features=500, bias=True)\n",
        "        # self.fc3=torch.nn.Linear(in_features=500, out_features=100, bias=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # x = self.fc2(x)\n",
        "        # x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "model = ModifiedResNet50(model) \n",
        "model=model.to(device)\n",
        "# print(model)\n",
        "import torchvision\n",
        "for name, param in model.named_parameters():\n",
        "    if name.startswith('fc'):\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, \"is trainable\")\n",
        "    else:\n",
        "        print(name, \"is not trainable\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762])\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "validset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in validloader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'Modmodel50-18.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
