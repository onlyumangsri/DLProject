{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Author: Umang Srivastav"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the save model from the exeuted file \"RN-50 and some test on variations\" or the one I have kept in the folder. Then execute the FIrst 18 layers + a FC layer modified model of RN50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y437hDbfyHR_",
        "outputId": "0045f5b2-2a10-481b-b167-ec182b0b257b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModifiedResNet50(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
            ")\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 52752954.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch [1/100], Test Accuracy: 29.69%\n",
            "Epoch [2/100], Test Accuracy: 32.76%\n",
            "Epoch [3/100], Test Accuracy: 35.17%\n",
            "Epoch [4/100], Test Accuracy: 35.10%\n",
            "Epoch [5/100], Test Accuracy: 34.43%\n",
            "Epoch [6/100], Test Accuracy: 35.95%\n",
            "Epoch [7/100], Test Accuracy: 37.12%\n",
            "Epoch [8/100], Test Accuracy: 38.17%\n",
            "Epoch [9/100], Test Accuracy: 36.50%\n",
            "Epoch [10/100], Test Accuracy: 38.27%\n",
            "Epoch [11/100], Test Accuracy: 36.96%\n",
            "Epoch [12/100], Test Accuracy: 36.63%\n",
            "Epoch [13/100], Test Accuracy: 39.07%\n",
            "Epoch [14/100], Test Accuracy: 38.93%\n",
            "Epoch [15/100], Test Accuracy: 38.79%\n",
            "Epoch [16/100], Test Accuracy: 37.82%\n",
            "Epoch [17/100], Test Accuracy: 37.67%\n",
            "Epoch [18/100], Test Accuracy: 39.64%\n",
            "Epoch [19/100], Test Accuracy: 39.79%\n",
            "Epoch [20/100], Test Accuracy: 40.48%\n",
            "Epoch [21/100], Test Accuracy: 38.50%\n",
            "Epoch [22/100], Test Accuracy: 38.35%\n",
            "Epoch [23/100], Test Accuracy: 40.06%\n",
            "Epoch [24/100], Test Accuracy: 39.14%\n",
            "Epoch [25/100], Test Accuracy: 39.84%\n",
            "Epoch [26/100], Test Accuracy: 39.12%\n",
            "Epoch [27/100], Test Accuracy: 39.45%\n",
            "Epoch [28/100], Test Accuracy: 38.25%\n",
            "Epoch [29/100], Test Accuracy: 39.51%\n",
            "Epoch [30/100], Test Accuracy: 39.22%\n",
            "Epoch [31/100], Test Accuracy: 39.39%\n",
            "Epoch [32/100], Test Accuracy: 39.28%\n",
            "Epoch [33/100], Test Accuracy: 39.09%\n",
            "Epoch [34/100], Test Accuracy: 40.92%\n",
            "Epoch [35/100], Test Accuracy: 38.23%\n",
            "Epoch [36/100], Test Accuracy: 38.00%\n",
            "Epoch [37/100], Test Accuracy: 38.68%\n",
            "Epoch [38/100], Test Accuracy: 38.35%\n",
            "Epoch [39/100], Test Accuracy: 39.03%\n",
            "Epoch [40/100], Test Accuracy: 40.39%\n",
            "Epoch [41/100], Test Accuracy: 37.86%\n",
            "Epoch [42/100], Test Accuracy: 39.95%\n",
            "Epoch [43/100], Test Accuracy: 38.95%\n",
            "Epoch [44/100], Test Accuracy: 39.46%\n",
            "Epoch [45/100], Test Accuracy: 39.62%\n",
            "Epoch [46/100], Test Accuracy: 38.31%\n",
            "Epoch [47/100], Test Accuracy: 40.12%\n",
            "Epoch [48/100], Test Accuracy: 39.60%\n",
            "Epoch [49/100], Test Accuracy: 38.72%\n",
            "Epoch [50/100], Test Accuracy: 39.95%\n",
            "Epoch [51/100], Test Accuracy: 39.15%\n",
            "Epoch [52/100], Test Accuracy: 39.24%\n",
            "Epoch [53/100], Test Accuracy: 39.74%\n",
            "Epoch [54/100], Test Accuracy: 39.36%\n",
            "Epoch [55/100], Test Accuracy: 39.35%\n",
            "Epoch [56/100], Test Accuracy: 38.35%\n",
            "Epoch [57/100], Test Accuracy: 37.95%\n",
            "Epoch [58/100], Test Accuracy: 38.22%\n",
            "Epoch [59/100], Test Accuracy: 40.62%\n",
            "Epoch [60/100], Test Accuracy: 38.95%\n",
            "Epoch [61/100], Test Accuracy: 39.41%\n",
            "Epoch [62/100], Test Accuracy: 39.70%\n",
            "Epoch [63/100], Test Accuracy: 39.78%\n",
            "Epoch [64/100], Test Accuracy: 38.98%\n",
            "Epoch [65/100], Test Accuracy: 37.68%\n",
            "Epoch [66/100], Test Accuracy: 39.05%\n",
            "Epoch [67/100], Test Accuracy: 38.72%\n",
            "Epoch [68/100], Test Accuracy: 39.91%\n",
            "Epoch [69/100], Test Accuracy: 39.80%\n",
            "Epoch [70/100], Test Accuracy: 39.17%\n",
            "Epoch [71/100], Test Accuracy: 38.77%\n",
            "Epoch [72/100], Test Accuracy: 40.21%\n",
            "Epoch [73/100], Test Accuracy: 39.97%\n",
            "Epoch [74/100], Test Accuracy: 39.95%\n",
            "Epoch [75/100], Test Accuracy: 40.08%\n",
            "Epoch [76/100], Test Accuracy: 38.48%\n",
            "Epoch [77/100], Test Accuracy: 39.14%\n",
            "Epoch [78/100], Test Accuracy: 39.01%\n",
            "Epoch [79/100], Test Accuracy: 39.45%\n",
            "Epoch [80/100], Test Accuracy: 39.86%\n",
            "Epoch [81/100], Test Accuracy: 39.89%\n",
            "Epoch [82/100], Test Accuracy: 38.90%\n",
            "Epoch [83/100], Test Accuracy: 38.33%\n",
            "Epoch [84/100], Test Accuracy: 39.24%\n",
            "Epoch [85/100], Test Accuracy: 38.91%\n",
            "Epoch [86/100], Test Accuracy: 38.46%\n",
            "Epoch [87/100], Test Accuracy: 40.26%\n",
            "Epoch [88/100], Test Accuracy: 39.63%\n",
            "Epoch [89/100], Test Accuracy: 39.30%\n",
            "Epoch [90/100], Test Accuracy: 39.17%\n",
            "Epoch [91/100], Test Accuracy: 38.83%\n",
            "Epoch [92/100], Test Accuracy: 40.19%\n",
            "Epoch [93/100], Test Accuracy: 38.57%\n",
            "Epoch [94/100], Test Accuracy: 39.32%\n",
            "Epoch [95/100], Test Accuracy: 38.59%\n",
            "Epoch [96/100], Test Accuracy: 39.06%\n",
            "Epoch [97/100], Test Accuracy: 39.48%\n",
            "Epoch [98/100], Test Accuracy: 39.17%\n",
            "Epoch [99/100], Test Accuracy: 39.01%\n",
            "Epoch [100/100], Test Accuracy: 39.43%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "model=models.resnet50(pretrained=False, num_classes=100)\n",
        "model.load_state_dict(torch.load('model50.pt'))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class ModifiedResNet50(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        \n",
        "        resnet=model#.resnet\n",
        "        self.conv1=resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        del self.layer2[3]\n",
        "        # del self.layer2[2].conv2\n",
        "        # del self.layer2[2].conv3\n",
        "        # del self.layer2[2].bn2\n",
        "        # del self.layer2[2].bn3\n",
        "        self.avgpool = resnet.avgpool\n",
        "        self.fc=torch.nn.Linear(in_features=512, out_features=100, bias=True)\n",
        "\n",
        "        # self.fc2=torch.nn.Linear(in_features=100, out_features=500, bias=True)\n",
        "        # self.fc3=torch.nn.Linear(in_features=500, out_features=100, bias=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # x = self.fc2(x)\n",
        "        # x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "model = ModifiedResNet50(model) \n",
        "model=model.to(device)\n",
        "print(model)\n",
        "import torchvision\n",
        "for name, param in model.named_parameters():\n",
        "    if name.startswith('fc'):\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# for name, param in model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name, \"is trainable\")\n",
        "#     else:\n",
        "#         print(name, \"is not trainable\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
        "                         std=[0.2673, 0.2564, 0.2762])\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "validset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in validloader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "torch.save(model.state_dict(), 'Modmodel50-18.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
