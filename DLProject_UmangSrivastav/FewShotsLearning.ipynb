{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Author: Umang Srivastav"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First Method: Taking 10% of the training set to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQPc9u1faKl6",
        "outputId": "93dbc1dc-38f1-4bb6-f53e-6785fa56300f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "157/157 [==============================] - 55s 43ms/step - loss: 2.7016 - accuracy: 0.2218\n",
            "Epoch 1: Test accuracy = 0.1194\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 2.3515 - accuracy: 0.2736\n",
            "Epoch 2: Test accuracy = 0.2388\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 2.1284 - accuracy: 0.3346\n",
            "Epoch 3: Test accuracy = 0.2157\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 2.0105 - accuracy: 0.3776\n",
            "Epoch 4: Test accuracy = 0.3488\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 2.2226 - accuracy: 0.3330\n",
            "Epoch 5: Test accuracy = 0.3497\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 2.0909 - accuracy: 0.3610\n",
            "Epoch 6: Test accuracy = 0.2606\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 2.0848 - accuracy: 0.3372\n",
            "Epoch 7: Test accuracy = 0.3006\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 2.3827 - accuracy: 0.2668\n",
            "Epoch 8: Test accuracy = 0.0960\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 2.4222 - accuracy: 0.2264\n",
            "Epoch 9: Test accuracy = 0.2068\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 2.4973 - accuracy: 0.2424\n",
            "Epoch 10: Test accuracy = 0.2782\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 2.1363 - accuracy: 0.2986\n",
            "Epoch 11: Test accuracy = 0.3135\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 2.1985 - accuracy: 0.2826\n",
            "Epoch 12: Test accuracy = 0.2165\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 2.2479 - accuracy: 0.2284\n",
            "Epoch 13: Test accuracy = 0.2077\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 2.1190 - accuracy: 0.2780\n",
            "Epoch 14: Test accuracy = 0.2772\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 2.2326 - accuracy: 0.2798\n",
            "Epoch 15: Test accuracy = 0.2065\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.9764 - accuracy: 0.3282\n",
            "Epoch 16: Test accuracy = 0.3168\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.9486 - accuracy: 0.3396\n",
            "Epoch 17: Test accuracy = 0.3111\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 2.1006 - accuracy: 0.3104\n",
            "Epoch 18: Test accuracy = 0.3241\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 2.0091 - accuracy: 0.3440\n",
            "Epoch 19: Test accuracy = 0.1875\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 2.0706 - accuracy: 0.3426\n",
            "Epoch 20: Test accuracy = 0.1462\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 2.0853 - accuracy: 0.3184\n",
            "Epoch 21: Test accuracy = 0.1376\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 2.0878 - accuracy: 0.3200\n",
            "Epoch 22: Test accuracy = 0.2802\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 2.0089 - accuracy: 0.3636\n",
            "Epoch 23: Test accuracy = 0.3168\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.9215 - accuracy: 0.3746\n",
            "Epoch 24: Test accuracy = 0.2797\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.9793 - accuracy: 0.3388\n",
            "Epoch 25: Test accuracy = 0.1004\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 2.1843 - accuracy: 0.3068\n",
            "Epoch 26: Test accuracy = 0.2084\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 2.1761 - accuracy: 0.3124\n",
            "Epoch 27: Test accuracy = 0.3147\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.9700 - accuracy: 0.3556\n",
            "Epoch 28: Test accuracy = 0.3453\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 2.0636 - accuracy: 0.3614\n",
            "Epoch 29: Test accuracy = 0.2928\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 2.0043 - accuracy: 0.3358\n",
            "Epoch 30: Test accuracy = 0.2191\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 2.0477 - accuracy: 0.3336\n",
            "Epoch 31: Test accuracy = 0.3653\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 2.0255 - accuracy: 0.3300\n",
            "Epoch 32: Test accuracy = 0.3278\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.8434 - accuracy: 0.3782\n",
            "Epoch 33: Test accuracy = 0.3573\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.7454 - accuracy: 0.3998\n",
            "Epoch 34: Test accuracy = 0.3255\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.7245 - accuracy: 0.4174\n",
            "Epoch 35: Test accuracy = 0.4048\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.7757 - accuracy: 0.4102\n",
            "Epoch 36: Test accuracy = 0.2479\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.7225 - accuracy: 0.4174\n",
            "Epoch 37: Test accuracy = 0.4132\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.7140 - accuracy: 0.4176\n",
            "Epoch 38: Test accuracy = 0.4177\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.7094 - accuracy: 0.4280\n",
            "Epoch 39: Test accuracy = 0.3913\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.6217 - accuracy: 0.4534\n",
            "Epoch 40: Test accuracy = 0.3110\n",
            "157/157 [==============================] - 7s 44ms/step - loss: 1.7089 - accuracy: 0.4374\n",
            "Epoch 41: Test accuracy = 0.3613\n",
            "157/157 [==============================] - 7s 44ms/step - loss: 1.6650 - accuracy: 0.4378\n",
            "Epoch 42: Test accuracy = 0.1134\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.7789 - accuracy: 0.4184\n",
            "Epoch 43: Test accuracy = 0.4049\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 1.7045 - accuracy: 0.4338\n",
            "Epoch 44: Test accuracy = 0.3858\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.8928 - accuracy: 0.3928\n",
            "Epoch 45: Test accuracy = 0.3077\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 1.8662 - accuracy: 0.3900\n",
            "Epoch 46: Test accuracy = 0.3597\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 1.8778 - accuracy: 0.3972\n",
            "Epoch 47: Test accuracy = 0.4312\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.7139 - accuracy: 0.4262\n",
            "Epoch 48: Test accuracy = 0.4457\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.8338 - accuracy: 0.3990\n",
            "Epoch 49: Test accuracy = 0.1201\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 2.0438 - accuracy: 0.3670\n",
            "Epoch 50: Test accuracy = 0.2103\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.8230 - accuracy: 0.3934\n",
            "Epoch 51: Test accuracy = 0.3420\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.7101 - accuracy: 0.4242\n",
            "Epoch 52: Test accuracy = 0.4200\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.6286 - accuracy: 0.4526\n",
            "Epoch 53: Test accuracy = 0.4565\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.6067 - accuracy: 0.4620\n",
            "Epoch 54: Test accuracy = 0.4556\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.5846 - accuracy: 0.4528\n",
            "Epoch 55: Test accuracy = 0.3187\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.7644 - accuracy: 0.3956\n",
            "Epoch 56: Test accuracy = 0.4359\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.5688 - accuracy: 0.4612\n",
            "Epoch 57: Test accuracy = 0.4334\n",
            "157/157 [==============================] - 7s 41ms/step - loss: 1.5751 - accuracy: 0.4494\n",
            "Epoch 58: Test accuracy = 0.4547\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.5462 - accuracy: 0.4630\n",
            "Epoch 59: Test accuracy = 0.4523\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.5954 - accuracy: 0.4516\n",
            "Epoch 60: Test accuracy = 0.4367\n",
            "157/157 [==============================] - 7s 41ms/step - loss: 1.5981 - accuracy: 0.4404\n",
            "Epoch 61: Test accuracy = 0.4281\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.4552 - accuracy: 0.4850\n",
            "Epoch 62: Test accuracy = 0.4715\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.4299 - accuracy: 0.4970\n",
            "Epoch 63: Test accuracy = 0.4514\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.4459 - accuracy: 0.4944\n",
            "Epoch 64: Test accuracy = 0.3880\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 1.4790 - accuracy: 0.4956\n",
            "Epoch 65: Test accuracy = 0.4324\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.4190 - accuracy: 0.5000\n",
            "Epoch 66: Test accuracy = 0.4659\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.3908 - accuracy: 0.5066\n",
            "Epoch 67: Test accuracy = 0.4928\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.4393 - accuracy: 0.5024\n",
            "Epoch 68: Test accuracy = 0.3385\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.4177 - accuracy: 0.5004\n",
            "Epoch 69: Test accuracy = 0.5224\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.3832 - accuracy: 0.5160\n",
            "Epoch 70: Test accuracy = 0.3906\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.4040 - accuracy: 0.5090\n",
            "Epoch 71: Test accuracy = 0.4611\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.3389 - accuracy: 0.5292\n",
            "Epoch 72: Test accuracy = 0.4629\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.2987 - accuracy: 0.5430\n",
            "Epoch 73: Test accuracy = 0.5476\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.3868 - accuracy: 0.5302\n",
            "Epoch 74: Test accuracy = 0.3767\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.6811 - accuracy: 0.4412\n",
            "Epoch 75: Test accuracy = 0.1623\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.6089 - accuracy: 0.4418\n",
            "Epoch 76: Test accuracy = 0.3822\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 1.4994 - accuracy: 0.4818\n",
            "Epoch 77: Test accuracy = 0.3155\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.6004 - accuracy: 0.4428\n",
            "Epoch 78: Test accuracy = 0.2933\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.5017 - accuracy: 0.4860\n",
            "Epoch 79: Test accuracy = 0.4831\n",
            "157/157 [==============================] - 7s 41ms/step - loss: 1.4376 - accuracy: 0.4940\n",
            "Epoch 80: Test accuracy = 0.3836\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.3757 - accuracy: 0.5188\n",
            "Epoch 81: Test accuracy = 0.5219\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.4628 - accuracy: 0.4912\n",
            "Epoch 82: Test accuracy = 0.2785\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.4572 - accuracy: 0.4972\n",
            "Epoch 83: Test accuracy = 0.4968\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.3420 - accuracy: 0.5290\n",
            "Epoch 84: Test accuracy = 0.5255\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.4954 - accuracy: 0.5032\n",
            "Epoch 85: Test accuracy = 0.5040\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.3562 - accuracy: 0.5350\n",
            "Epoch 86: Test accuracy = 0.4691\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.5020 - accuracy: 0.4968\n",
            "Epoch 87: Test accuracy = 0.1103\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.7100 - accuracy: 0.4404\n",
            "Epoch 88: Test accuracy = 0.2253\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.5981 - accuracy: 0.4386\n",
            "Epoch 89: Test accuracy = 0.4353\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.4613 - accuracy: 0.5004\n",
            "Epoch 90: Test accuracy = 0.4600\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 1.4237 - accuracy: 0.5092\n",
            "Epoch 91: Test accuracy = 0.4576\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 1.3667 - accuracy: 0.5222\n",
            "Epoch 92: Test accuracy = 0.5262\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.3033 - accuracy: 0.5358\n",
            "Epoch 93: Test accuracy = 0.5700\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.2531 - accuracy: 0.5692\n",
            "Epoch 94: Test accuracy = 0.5021\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 1.3485 - accuracy: 0.5304\n",
            "Epoch 95: Test accuracy = 0.5291\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.2654 - accuracy: 0.5604\n",
            "Epoch 96: Test accuracy = 0.5623\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.2326 - accuracy: 0.5650\n",
            "Epoch 97: Test accuracy = 0.5699\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 1.2131 - accuracy: 0.5756\n",
            "Epoch 98: Test accuracy = 0.5623\n",
            "157/157 [==============================] - 6s 41ms/step - loss: 1.1980 - accuracy: 0.5802\n",
            "Epoch 99: Test accuracy = 0.5619\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 1.2049 - accuracy: 0.5836\n",
            "Epoch 100: Test accuracy = 0.4894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "model = keras.applications.resnet50.ResNet50(weights=None, input_shape=x_train.shape[1:], classes=10)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "num_samples_per_epoch = int(0.1 * x_train.shape[0])\n",
        "\n",
        "for epoch in range(100):\n",
        "    indices = np.random.choice(x_train.shape[0], size=num_samples_per_epoch, replace=False)\n",
        "    x_train_subset, y_train_subset = x_train[indices], y_train[indices]\n",
        "\n",
        "    model.fit(x_train_subset, y_train_subset, batch_size=32, epochs=1, verbose=1)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Epoch {epoch+1}: Test accuracy = {test_acc:.4f}\")\n",
        "\n",
        "model.save(\"mod10per.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDPeDFzVKTHB"
      },
      "outputs": [],
      "source": [
        "tf.keras.models.save_model(model, 'mod10per.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second Method: Using Transfer Learning (RN-50 on imagenet) with Data Augumentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMYff3wvaM_8",
        "outputId": "b0210460-a6ab-4ee8-c098-9c59649d343b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy = 0.1054\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "resnet = keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\n",
        "\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
        "x = keras.layers.Dense(10, activation='softmax')(x)\n",
        "model = keras.models.Model(resnet.input, x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "num_samples = 1500\n",
        "\n",
        "\n",
        "few_shot_indices = np.random.choice(x_train.shape[0], size=num_samples, replace=False)\n",
        "x_train_few_shot, y_train_few_shot = x_train[few_shot_indices], y_train[few_shot_indices]\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='reflect')\n",
        "\n",
        "history = model.fit(datagen.flow(x_train_few_shot, y_train_few_shot, batch_size=32), \n",
        "                    steps_per_epoch=len(x_train_few_shot) // 32, \n",
        "                    epochs=200, \n",
        "                    verbose=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy = {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "tf.keras.models.save_model(model, 'modDataAug.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Third Method: Using 50 samples per class of the train set to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I25Ddosi6mcq",
        "outputId": "8c0d413a-4fa2-4eaf-8525-fb27ae95dcd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/100], Step [10/50], Loss: 55.2695\n",
            "Epoch [1/100], Step [20/50], Loss: 63.5718\n",
            "Epoch [1/100], Step [30/50], Loss: 4.2903\n",
            "Epoch [1/100], Step [40/50], Loss: 4.8622\n",
            "Epoch [1/100], Step [50/50], Loss: 3.3820\n",
            "Epoch [2/100], Step [10/50], Loss: 2.3510\n",
            "Epoch [2/100], Step [20/50], Loss: 3.1156\n",
            "Epoch [2/100], Step [30/50], Loss: 2.5117\n",
            "Epoch [2/100], Step [40/50], Loss: 2.6587\n",
            "Epoch [2/100], Step [50/50], Loss: 2.2569\n",
            "Epoch [3/100], Step [10/50], Loss: 2.1706\n",
            "Epoch [3/100], Step [20/50], Loss: 3.2530\n",
            "Epoch [3/100], Step [30/50], Loss: 2.3451\n",
            "Epoch [3/100], Step [40/50], Loss: 2.1797\n",
            "Epoch [3/100], Step [50/50], Loss: 2.3652\n",
            "Epoch [4/100], Step [10/50], Loss: 2.2100\n",
            "Epoch [4/100], Step [20/50], Loss: 2.4540\n",
            "Epoch [4/100], Step [30/50], Loss: 2.3355\n",
            "Epoch [4/100], Step [40/50], Loss: 2.2884\n",
            "Epoch [4/100], Step [50/50], Loss: 2.3245\n",
            "Epoch [5/100], Step [10/50], Loss: 2.2336\n",
            "Epoch [5/100], Step [20/50], Loss: 2.2878\n",
            "Epoch [5/100], Step [30/50], Loss: 2.4828\n",
            "Epoch [5/100], Step [40/50], Loss: 2.2201\n",
            "Epoch [5/100], Step [50/50], Loss: 2.2844\n",
            "Epoch [6/100], Step [10/50], Loss: 2.3553\n",
            "Epoch [6/100], Step [20/50], Loss: 2.3511\n",
            "Epoch [6/100], Step [30/50], Loss: 2.3936\n",
            "Epoch [6/100], Step [40/50], Loss: 2.4053\n",
            "Epoch [6/100], Step [50/50], Loss: 2.5207\n",
            "Epoch [7/100], Step [10/50], Loss: 2.2426\n",
            "Epoch [7/100], Step [20/50], Loss: 2.2862\n",
            "Epoch [7/100], Step [30/50], Loss: 2.3153\n",
            "Epoch [7/100], Step [40/50], Loss: 2.2768\n",
            "Epoch [7/100], Step [50/50], Loss: 2.2552\n",
            "Epoch [8/100], Step [10/50], Loss: 2.3111\n",
            "Epoch [8/100], Step [20/50], Loss: 2.3431\n",
            "Epoch [8/100], Step [30/50], Loss: 2.2859\n",
            "Epoch [8/100], Step [40/50], Loss: 2.4329\n",
            "Epoch [8/100], Step [50/50], Loss: 2.1867\n",
            "Epoch [9/100], Step [10/50], Loss: 2.4182\n",
            "Epoch [9/100], Step [20/50], Loss: 2.2709\n",
            "Epoch [9/100], Step [30/50], Loss: 2.3132\n",
            "Epoch [9/100], Step [40/50], Loss: 2.3018\n",
            "Epoch [9/100], Step [50/50], Loss: 2.3360\n",
            "Epoch [10/100], Step [10/50], Loss: 2.3099\n",
            "Epoch [10/100], Step [20/50], Loss: 2.2594\n",
            "Epoch [10/100], Step [30/50], Loss: 2.1434\n",
            "Epoch [10/100], Step [40/50], Loss: 2.4495\n",
            "Epoch [10/100], Step [50/50], Loss: 2.2587\n",
            "Epoch [11/100], Step [10/50], Loss: 2.4033\n",
            "Epoch [11/100], Step [20/50], Loss: 2.5479\n",
            "Epoch [11/100], Step [30/50], Loss: 2.3275\n",
            "Epoch [11/100], Step [40/50], Loss: 2.3273\n",
            "Epoch [11/100], Step [50/50], Loss: 2.3262\n",
            "Epoch [12/100], Step [10/50], Loss: 2.3414\n",
            "Epoch [12/100], Step [20/50], Loss: 2.2844\n",
            "Epoch [12/100], Step [30/50], Loss: 2.5010\n",
            "Epoch [12/100], Step [40/50], Loss: 2.3424\n",
            "Epoch [12/100], Step [50/50], Loss: 2.3127\n",
            "Epoch [13/100], Step [10/50], Loss: 2.3054\n",
            "Epoch [13/100], Step [20/50], Loss: 2.3199\n",
            "Epoch [13/100], Step [30/50], Loss: 2.3067\n",
            "Epoch [13/100], Step [40/50], Loss: 2.2680\n",
            "Epoch [13/100], Step [50/50], Loss: 2.3519\n",
            "Epoch [14/100], Step [10/50], Loss: 2.3915\n",
            "Epoch [14/100], Step [20/50], Loss: 2.3622\n",
            "Epoch [14/100], Step [30/50], Loss: 2.3084\n",
            "Epoch [14/100], Step [40/50], Loss: 2.3138\n",
            "Epoch [14/100], Step [50/50], Loss: 2.4147\n",
            "Epoch [15/100], Step [10/50], Loss: 2.3449\n",
            "Epoch [15/100], Step [20/50], Loss: 2.2946\n",
            "Epoch [15/100], Step [30/50], Loss: 2.3850\n",
            "Epoch [15/100], Step [40/50], Loss: 2.3053\n",
            "Epoch [15/100], Step [50/50], Loss: 2.3139\n",
            "Epoch [16/100], Step [10/50], Loss: 2.3078\n",
            "Epoch [16/100], Step [20/50], Loss: 2.2919\n",
            "Epoch [16/100], Step [30/50], Loss: 2.4460\n",
            "Epoch [16/100], Step [40/50], Loss: 2.3282\n",
            "Epoch [16/100], Step [50/50], Loss: 2.2950\n",
            "Epoch [17/100], Step [10/50], Loss: 2.3133\n",
            "Epoch [17/100], Step [20/50], Loss: 2.3664\n",
            "Epoch [17/100], Step [30/50], Loss: 2.3465\n",
            "Epoch [17/100], Step [40/50], Loss: 2.3367\n",
            "Epoch [17/100], Step [50/50], Loss: 2.3443\n",
            "Epoch [18/100], Step [10/50], Loss: 2.3295\n",
            "Epoch [18/100], Step [20/50], Loss: 2.2437\n",
            "Epoch [18/100], Step [30/50], Loss: 2.3569\n",
            "Epoch [18/100], Step [40/50], Loss: 2.2870\n",
            "Epoch [18/100], Step [50/50], Loss: 2.4324\n",
            "Epoch [19/100], Step [10/50], Loss: 2.3019\n",
            "Epoch [19/100], Step [20/50], Loss: 2.3408\n",
            "Epoch [19/100], Step [30/50], Loss: 2.3591\n",
            "Epoch [19/100], Step [40/50], Loss: 2.3209\n",
            "Epoch [19/100], Step [50/50], Loss: 2.3183\n",
            "Epoch [20/100], Step [10/50], Loss: 2.2410\n",
            "Epoch [20/100], Step [20/50], Loss: 2.3727\n",
            "Epoch [20/100], Step [30/50], Loss: 2.2973\n",
            "Epoch [20/100], Step [40/50], Loss: 2.4637\n",
            "Epoch [20/100], Step [50/50], Loss: 2.2968\n",
            "Epoch [21/100], Step [10/50], Loss: 2.3285\n",
            "Epoch [21/100], Step [20/50], Loss: 2.2869\n",
            "Epoch [21/100], Step [30/50], Loss: 2.2749\n",
            "Epoch [21/100], Step [40/50], Loss: 2.2776\n",
            "Epoch [21/100], Step [50/50], Loss: 2.2967\n",
            "Epoch [22/100], Step [10/50], Loss: 2.2243\n",
            "Epoch [22/100], Step [20/50], Loss: 2.2999\n",
            "Epoch [22/100], Step [30/50], Loss: 2.2581\n",
            "Epoch [22/100], Step [40/50], Loss: 2.3072\n",
            "Epoch [22/100], Step [50/50], Loss: 2.2282\n",
            "Epoch [23/100], Step [10/50], Loss: 2.8159\n",
            "Epoch [23/100], Step [20/50], Loss: 2.4335\n",
            "Epoch [23/100], Step [30/50], Loss: 2.4036\n",
            "Epoch [23/100], Step [40/50], Loss: 2.4001\n",
            "Epoch [23/100], Step [50/50], Loss: 2.3864\n",
            "Epoch [24/100], Step [10/50], Loss: 2.3863\n",
            "Epoch [24/100], Step [20/50], Loss: 2.2661\n",
            "Epoch [24/100], Step [30/50], Loss: 2.3322\n",
            "Epoch [24/100], Step [40/50], Loss: 2.3951\n",
            "Epoch [24/100], Step [50/50], Loss: 2.4380\n",
            "Epoch [25/100], Step [10/50], Loss: 2.3699\n",
            "Epoch [25/100], Step [20/50], Loss: 2.3966\n",
            "Epoch [25/100], Step [30/50], Loss: 2.3571\n",
            "Epoch [25/100], Step [40/50], Loss: 2.2264\n",
            "Epoch [25/100], Step [50/50], Loss: 2.2593\n",
            "Epoch [26/100], Step [10/50], Loss: 2.3086\n",
            "Epoch [26/100], Step [20/50], Loss: 2.3902\n",
            "Epoch [26/100], Step [30/50], Loss: 2.4967\n",
            "Epoch [26/100], Step [40/50], Loss: 2.4698\n",
            "Epoch [26/100], Step [50/50], Loss: 2.3601\n",
            "Epoch [27/100], Step [10/50], Loss: 2.2576\n",
            "Epoch [27/100], Step [20/50], Loss: 2.3018\n",
            "Epoch [27/100], Step [30/50], Loss: 2.2857\n",
            "Epoch [27/100], Step [40/50], Loss: 2.3490\n",
            "Epoch [27/100], Step [50/50], Loss: 2.3710\n",
            "Epoch [28/100], Step [10/50], Loss: 2.2535\n",
            "Epoch [28/100], Step [20/50], Loss: 2.3391\n",
            "Epoch [28/100], Step [30/50], Loss: 2.1792\n",
            "Epoch [28/100], Step [40/50], Loss: 2.4004\n",
            "Epoch [28/100], Step [50/50], Loss: 2.4028\n",
            "Epoch [29/100], Step [10/50], Loss: 2.2469\n",
            "Epoch [29/100], Step [20/50], Loss: 2.2500\n",
            "Epoch [29/100], Step [30/50], Loss: 2.2554\n",
            "Epoch [29/100], Step [40/50], Loss: 2.4397\n",
            "Epoch [29/100], Step [50/50], Loss: 2.2122\n",
            "Epoch [30/100], Step [10/50], Loss: 2.1439\n",
            "Epoch [30/100], Step [20/50], Loss: 2.3109\n",
            "Epoch [30/100], Step [30/50], Loss: 2.4947\n",
            "Epoch [30/100], Step [40/50], Loss: 2.5289\n",
            "Epoch [30/100], Step [50/50], Loss: 2.3407\n",
            "Epoch [31/100], Step [10/50], Loss: 2.4326\n",
            "Epoch [31/100], Step [20/50], Loss: 2.5817\n",
            "Epoch [31/100], Step [30/50], Loss: 2.2367\n",
            "Epoch [31/100], Step [40/50], Loss: 2.3003\n",
            "Epoch [31/100], Step [50/50], Loss: 2.2059\n",
            "Epoch [32/100], Step [10/50], Loss: 2.2563\n",
            "Epoch [32/100], Step [20/50], Loss: 2.2896\n",
            "Epoch [32/100], Step [30/50], Loss: 2.2947\n",
            "Epoch [32/100], Step [40/50], Loss: 2.3737\n",
            "Epoch [32/100], Step [50/50], Loss: 2.3416\n",
            "Epoch [33/100], Step [10/50], Loss: 2.3355\n",
            "Epoch [33/100], Step [20/50], Loss: 2.3189\n",
            "Epoch [33/100], Step [30/50], Loss: 2.3136\n",
            "Epoch [33/100], Step [40/50], Loss: 2.4335\n",
            "Epoch [33/100], Step [50/50], Loss: 2.3365\n",
            "Epoch [34/100], Step [10/50], Loss: 2.2869\n",
            "Epoch [34/100], Step [20/50], Loss: 2.4870\n",
            "Epoch [34/100], Step [30/50], Loss: 2.3640\n",
            "Epoch [34/100], Step [40/50], Loss: 2.2898\n",
            "Epoch [34/100], Step [50/50], Loss: 2.3964\n",
            "Epoch [35/100], Step [10/50], Loss: 2.3283\n",
            "Epoch [35/100], Step [20/50], Loss: 2.3246\n",
            "Epoch [35/100], Step [30/50], Loss: 2.2904\n",
            "Epoch [35/100], Step [40/50], Loss: 2.4006\n",
            "Epoch [35/100], Step [50/50], Loss: 2.3660\n",
            "Epoch [36/100], Step [10/50], Loss: 2.3477\n",
            "Epoch [36/100], Step [20/50], Loss: 2.3003\n",
            "Epoch [36/100], Step [30/50], Loss: 2.3319\n",
            "Epoch [36/100], Step [40/50], Loss: 2.2808\n",
            "Epoch [36/100], Step [50/50], Loss: 2.4347\n",
            "Epoch [37/100], Step [10/50], Loss: 2.2883\n",
            "Epoch [37/100], Step [20/50], Loss: 2.4109\n",
            "Epoch [37/100], Step [30/50], Loss: 2.4813\n",
            "Epoch [37/100], Step [40/50], Loss: 2.4075\n",
            "Epoch [37/100], Step [50/50], Loss: 2.2375\n",
            "Epoch [38/100], Step [10/50], Loss: 2.2674\n",
            "Epoch [38/100], Step [20/50], Loss: 2.3288\n",
            "Epoch [38/100], Step [30/50], Loss: 2.3170\n",
            "Epoch [38/100], Step [40/50], Loss: 2.3524\n",
            "Epoch [38/100], Step [50/50], Loss: 2.3789\n",
            "Epoch [39/100], Step [10/50], Loss: 2.2921\n",
            "Epoch [39/100], Step [20/50], Loss: 2.3716\n",
            "Epoch [39/100], Step [30/50], Loss: 2.3755\n",
            "Epoch [39/100], Step [40/50], Loss: 2.3342\n",
            "Epoch [39/100], Step [50/50], Loss: 2.3285\n",
            "Epoch [40/100], Step [10/50], Loss: 2.2764\n",
            "Epoch [40/100], Step [20/50], Loss: 2.2533\n",
            "Epoch [40/100], Step [30/50], Loss: 2.2357\n",
            "Epoch [40/100], Step [40/50], Loss: 2.4833\n",
            "Epoch [40/100], Step [50/50], Loss: 2.2774\n",
            "Epoch [41/100], Step [10/50], Loss: 2.3662\n",
            "Epoch [41/100], Step [20/50], Loss: 2.2848\n",
            "Epoch [41/100], Step [30/50], Loss: 2.2166\n",
            "Epoch [41/100], Step [40/50], Loss: 2.4218\n",
            "Epoch [41/100], Step [50/50], Loss: 2.3322\n",
            "Epoch [42/100], Step [10/50], Loss: 2.1716\n",
            "Epoch [42/100], Step [20/50], Loss: 2.2869\n",
            "Epoch [42/100], Step [30/50], Loss: 2.2874\n",
            "Epoch [42/100], Step [40/50], Loss: 2.2844\n",
            "Epoch [42/100], Step [50/50], Loss: 2.2105\n",
            "Epoch [43/100], Step [10/50], Loss: 2.3631\n",
            "Epoch [43/100], Step [20/50], Loss: 2.4392\n",
            "Epoch [43/100], Step [30/50], Loss: 2.2387\n",
            "Epoch [43/100], Step [40/50], Loss: 2.4792\n",
            "Epoch [43/100], Step [50/50], Loss: 2.3203\n",
            "Epoch [44/100], Step [10/50], Loss: 2.1350\n",
            "Epoch [44/100], Step [20/50], Loss: 2.3140\n",
            "Epoch [44/100], Step [30/50], Loss: 2.2633\n",
            "Epoch [44/100], Step [40/50], Loss: 2.2917\n",
            "Epoch [44/100], Step [50/50], Loss: 2.3104\n",
            "Epoch [45/100], Step [10/50], Loss: 2.3659\n",
            "Epoch [45/100], Step [20/50], Loss: 2.3138\n",
            "Epoch [45/100], Step [30/50], Loss: 2.3555\n",
            "Epoch [45/100], Step [40/50], Loss: 2.3626\n",
            "Epoch [45/100], Step [50/50], Loss: 2.3953\n",
            "Epoch [46/100], Step [10/50], Loss: 2.3175\n",
            "Epoch [46/100], Step [20/50], Loss: 2.3267\n",
            "Epoch [46/100], Step [30/50], Loss: 2.3429\n",
            "Epoch [46/100], Step [40/50], Loss: 2.3006\n",
            "Epoch [46/100], Step [50/50], Loss: 2.2765\n",
            "Epoch [47/100], Step [10/50], Loss: 2.4127\n",
            "Epoch [47/100], Step [20/50], Loss: 2.2461\n",
            "Epoch [47/100], Step [30/50], Loss: 2.3108\n",
            "Epoch [47/100], Step [40/50], Loss: 2.0930\n",
            "Epoch [47/100], Step [50/50], Loss: 2.2516\n",
            "Epoch [48/100], Step [10/50], Loss: 2.3001\n",
            "Epoch [48/100], Step [20/50], Loss: 2.1369\n",
            "Epoch [48/100], Step [30/50], Loss: 2.2136\n",
            "Epoch [48/100], Step [40/50], Loss: 2.3801\n",
            "Epoch [48/100], Step [50/50], Loss: 2.2739\n",
            "Epoch [49/100], Step [10/50], Loss: 2.4446\n",
            "Epoch [49/100], Step [20/50], Loss: 2.2902\n",
            "Epoch [49/100], Step [30/50], Loss: 2.4624\n",
            "Epoch [49/100], Step [40/50], Loss: 2.3483\n",
            "Epoch [49/100], Step [50/50], Loss: 2.3445\n",
            "Epoch [50/100], Step [10/50], Loss: 2.2697\n",
            "Epoch [50/100], Step [20/50], Loss: 2.3543\n",
            "Epoch [50/100], Step [30/50], Loss: 2.2840\n",
            "Epoch [50/100], Step [40/50], Loss: 2.3295\n",
            "Epoch [50/100], Step [50/50], Loss: 2.1722\n",
            "Epoch [51/100], Step [10/50], Loss: 2.3115\n",
            "Epoch [51/100], Step [20/50], Loss: 2.7007\n",
            "Epoch [51/100], Step [30/50], Loss: 2.2272\n",
            "Epoch [51/100], Step [40/50], Loss: 2.0962\n",
            "Epoch [51/100], Step [50/50], Loss: 2.3280\n",
            "Epoch [52/100], Step [10/50], Loss: 2.3368\n",
            "Epoch [52/100], Step [20/50], Loss: 2.3061\n",
            "Epoch [52/100], Step [30/50], Loss: 2.1401\n",
            "Epoch [52/100], Step [40/50], Loss: 2.2450\n",
            "Epoch [52/100], Step [50/50], Loss: 2.2360\n",
            "Epoch [53/100], Step [10/50], Loss: 2.2531\n",
            "Epoch [53/100], Step [20/50], Loss: 2.3815\n",
            "Epoch [53/100], Step [30/50], Loss: 2.3645\n",
            "Epoch [53/100], Step [40/50], Loss: 2.3387\n",
            "Epoch [53/100], Step [50/50], Loss: 2.2755\n",
            "Epoch [54/100], Step [10/50], Loss: 2.3217\n",
            "Epoch [54/100], Step [20/50], Loss: 2.2340\n",
            "Epoch [54/100], Step [30/50], Loss: 2.2802\n",
            "Epoch [54/100], Step [40/50], Loss: 2.2467\n",
            "Epoch [54/100], Step [50/50], Loss: 2.4649\n",
            "Epoch [55/100], Step [10/50], Loss: 2.3672\n",
            "Epoch [55/100], Step [20/50], Loss: 2.2013\n",
            "Epoch [55/100], Step [30/50], Loss: 2.1344\n",
            "Epoch [55/100], Step [40/50], Loss: 2.3483\n",
            "Epoch [55/100], Step [50/50], Loss: 2.1989\n",
            "Epoch [56/100], Step [10/50], Loss: 2.0174\n",
            "Epoch [56/100], Step [20/50], Loss: 2.2898\n",
            "Epoch [56/100], Step [30/50], Loss: 2.3364\n",
            "Epoch [56/100], Step [40/50], Loss: 2.2237\n",
            "Epoch [56/100], Step [50/50], Loss: 2.1899\n",
            "Epoch [57/100], Step [10/50], Loss: 2.4113\n",
            "Epoch [57/100], Step [20/50], Loss: 2.1543\n",
            "Epoch [57/100], Step [30/50], Loss: 2.4611\n",
            "Epoch [57/100], Step [40/50], Loss: 2.4347\n",
            "Epoch [57/100], Step [50/50], Loss: 2.2954\n",
            "Epoch [58/100], Step [10/50], Loss: 2.1983\n",
            "Epoch [58/100], Step [20/50], Loss: 2.2482\n",
            "Epoch [58/100], Step [30/50], Loss: 2.2751\n",
            "Epoch [58/100], Step [40/50], Loss: 2.1793\n",
            "Epoch [58/100], Step [50/50], Loss: 2.5595\n",
            "Epoch [59/100], Step [10/50], Loss: 2.2638\n",
            "Epoch [59/100], Step [20/50], Loss: 2.2825\n",
            "Epoch [59/100], Step [30/50], Loss: 2.2554\n",
            "Epoch [59/100], Step [40/50], Loss: 2.3931\n",
            "Epoch [59/100], Step [50/50], Loss: 2.2927\n",
            "Epoch [60/100], Step [10/50], Loss: 2.2794\n",
            "Epoch [60/100], Step [20/50], Loss: 2.4165\n",
            "Epoch [60/100], Step [30/50], Loss: 2.3566\n",
            "Epoch [60/100], Step [40/50], Loss: 2.2933\n",
            "Epoch [60/100], Step [50/50], Loss: 2.3176\n",
            "Epoch [61/100], Step [10/50], Loss: 2.3539\n",
            "Epoch [61/100], Step [20/50], Loss: 2.2890\n",
            "Epoch [61/100], Step [30/50], Loss: 2.2705\n",
            "Epoch [61/100], Step [40/50], Loss: 2.3285\n",
            "Epoch [61/100], Step [50/50], Loss: 2.3653\n",
            "Epoch [62/100], Step [10/50], Loss: 2.2475\n",
            "Epoch [62/100], Step [20/50], Loss: 2.4692\n",
            "Epoch [62/100], Step [30/50], Loss: 2.4279\n",
            "Epoch [62/100], Step [40/50], Loss: 2.4131\n",
            "Epoch [62/100], Step [50/50], Loss: 2.3486\n",
            "Epoch [63/100], Step [10/50], Loss: 2.2887\n",
            "Epoch [63/100], Step [20/50], Loss: 2.3336\n",
            "Epoch [63/100], Step [30/50], Loss: 2.2980\n",
            "Epoch [63/100], Step [40/50], Loss: 2.3907\n",
            "Epoch [63/100], Step [50/50], Loss: 2.2988\n",
            "Epoch [64/100], Step [10/50], Loss: 2.3044\n",
            "Epoch [64/100], Step [20/50], Loss: 2.3927\n",
            "Epoch [64/100], Step [30/50], Loss: 2.3266\n",
            "Epoch [64/100], Step [40/50], Loss: 2.2765\n",
            "Epoch [64/100], Step [50/50], Loss: 2.1452\n",
            "Epoch [65/100], Step [10/50], Loss: 2.2525\n",
            "Epoch [65/100], Step [20/50], Loss: 2.3150\n",
            "Epoch [65/100], Step [30/50], Loss: 2.3334\n",
            "Epoch [65/100], Step [40/50], Loss: 2.2664\n",
            "Epoch [65/100], Step [50/50], Loss: 2.2247\n",
            "Epoch [66/100], Step [10/50], Loss: 2.3833\n",
            "Epoch [66/100], Step [20/50], Loss: 2.4495\n",
            "Epoch [66/100], Step [30/50], Loss: 2.3389\n",
            "Epoch [66/100], Step [40/50], Loss: 2.4053\n",
            "Epoch [66/100], Step [50/50], Loss: 2.3798\n",
            "Epoch [67/100], Step [10/50], Loss: 2.3034\n",
            "Epoch [67/100], Step [20/50], Loss: 2.1843\n",
            "Epoch [67/100], Step [30/50], Loss: 2.2590\n",
            "Epoch [67/100], Step [40/50], Loss: 2.3965\n",
            "Epoch [67/100], Step [50/50], Loss: 2.3273\n",
            "Epoch [68/100], Step [10/50], Loss: 2.3175\n",
            "Epoch [68/100], Step [20/50], Loss: 2.3469\n",
            "Epoch [68/100], Step [30/50], Loss: 2.3878\n",
            "Epoch [68/100], Step [40/50], Loss: 2.2631\n",
            "Epoch [68/100], Step [50/50], Loss: 2.6112\n",
            "Epoch [69/100], Step [10/50], Loss: 2.0900\n",
            "Epoch [69/100], Step [20/50], Loss: 2.1829\n",
            "Epoch [69/100], Step [30/50], Loss: 2.0171\n",
            "Epoch [69/100], Step [40/50], Loss: 2.5272\n",
            "Epoch [69/100], Step [50/50], Loss: 2.2331\n",
            "Epoch [70/100], Step [10/50], Loss: 2.4441\n",
            "Epoch [70/100], Step [20/50], Loss: 2.4538\n",
            "Epoch [70/100], Step [30/50], Loss: 2.3169\n",
            "Epoch [70/100], Step [40/50], Loss: 2.1964\n",
            "Epoch [70/100], Step [50/50], Loss: 2.4910\n",
            "Epoch [71/100], Step [10/50], Loss: 2.1357\n",
            "Epoch [71/100], Step [20/50], Loss: 2.3104\n",
            "Epoch [71/100], Step [30/50], Loss: 2.2696\n",
            "Epoch [71/100], Step [40/50], Loss: 2.1353\n",
            "Epoch [71/100], Step [50/50], Loss: 2.2187\n",
            "Epoch [72/100], Step [10/50], Loss: 2.3339\n",
            "Epoch [72/100], Step [20/50], Loss: 2.3875\n",
            "Epoch [72/100], Step [30/50], Loss: 2.1848\n",
            "Epoch [72/100], Step [40/50], Loss: 2.0440\n",
            "Epoch [72/100], Step [50/50], Loss: 2.3568\n",
            "Epoch [73/100], Step [10/50], Loss: 2.1951\n",
            "Epoch [73/100], Step [20/50], Loss: 2.3178\n",
            "Epoch [73/100], Step [30/50], Loss: 2.4156\n",
            "Epoch [73/100], Step [40/50], Loss: 2.2041\n",
            "Epoch [73/100], Step [50/50], Loss: 2.1474\n",
            "Epoch [74/100], Step [10/50], Loss: 2.5278\n",
            "Epoch [74/100], Step [20/50], Loss: 2.3422\n",
            "Epoch [74/100], Step [30/50], Loss: 2.3998\n",
            "Epoch [74/100], Step [40/50], Loss: 2.3962\n",
            "Epoch [74/100], Step [50/50], Loss: 2.2723\n",
            "Epoch [75/100], Step [10/50], Loss: 2.4532\n",
            "Epoch [75/100], Step [20/50], Loss: 2.1600\n",
            "Epoch [75/100], Step [30/50], Loss: 2.2411\n",
            "Epoch [75/100], Step [40/50], Loss: 2.1121\n",
            "Epoch [75/100], Step [50/50], Loss: 2.2327\n",
            "Epoch [76/100], Step [10/50], Loss: 2.4138\n",
            "Epoch [76/100], Step [20/50], Loss: 2.1771\n",
            "Epoch [76/100], Step [30/50], Loss: 2.1933\n",
            "Epoch [76/100], Step [40/50], Loss: 2.3850\n",
            "Epoch [76/100], Step [50/50], Loss: 2.3942\n",
            "Epoch [77/100], Step [10/50], Loss: 2.3280\n",
            "Epoch [77/100], Step [20/50], Loss: 2.4210\n",
            "Epoch [77/100], Step [30/50], Loss: 2.4048\n",
            "Epoch [77/100], Step [40/50], Loss: 2.6335\n",
            "Epoch [77/100], Step [50/50], Loss: 2.1667\n",
            "Epoch [78/100], Step [10/50], Loss: 2.2868\n",
            "Epoch [78/100], Step [20/50], Loss: 2.1704\n",
            "Epoch [78/100], Step [30/50], Loss: 2.3751\n",
            "Epoch [78/100], Step [40/50], Loss: 2.2513\n",
            "Epoch [78/100], Step [50/50], Loss: 2.2965\n",
            "Epoch [79/100], Step [10/50], Loss: 2.1798\n",
            "Epoch [79/100], Step [20/50], Loss: 2.1424\n",
            "Epoch [79/100], Step [30/50], Loss: 2.3336\n",
            "Epoch [79/100], Step [40/50], Loss: 2.3366\n",
            "Epoch [79/100], Step [50/50], Loss: 2.0049\n",
            "Epoch [80/100], Step [10/50], Loss: 2.2667\n",
            "Epoch [80/100], Step [20/50], Loss: 2.2573\n",
            "Epoch [80/100], Step [30/50], Loss: 2.4475\n",
            "Epoch [80/100], Step [40/50], Loss: 2.3994\n",
            "Epoch [80/100], Step [50/50], Loss: 2.4097\n",
            "Epoch [81/100], Step [10/50], Loss: 2.3927\n",
            "Epoch [81/100], Step [20/50], Loss: 2.3957\n",
            "Epoch [81/100], Step [30/50], Loss: 2.1042\n",
            "Epoch [81/100], Step [40/50], Loss: 2.5439\n",
            "Epoch [81/100], Step [50/50], Loss: 2.4688\n",
            "Epoch [82/100], Step [10/50], Loss: 2.4700\n",
            "Epoch [82/100], Step [20/50], Loss: 2.2276\n",
            "Epoch [82/100], Step [30/50], Loss: 2.4802\n",
            "Epoch [82/100], Step [40/50], Loss: 1.9993\n",
            "Epoch [82/100], Step [50/50], Loss: 2.3729\n",
            "Epoch [83/100], Step [10/50], Loss: 2.2927\n",
            "Epoch [83/100], Step [20/50], Loss: 2.1483\n",
            "Epoch [83/100], Step [30/50], Loss: 2.0989\n",
            "Epoch [83/100], Step [40/50], Loss: 2.1813\n",
            "Epoch [83/100], Step [50/50], Loss: 2.4619\n",
            "Epoch [84/100], Step [10/50], Loss: 2.2148\n",
            "Epoch [84/100], Step [20/50], Loss: 2.0812\n",
            "Epoch [84/100], Step [30/50], Loss: 2.3671\n",
            "Epoch [84/100], Step [40/50], Loss: 2.6785\n",
            "Epoch [84/100], Step [50/50], Loss: 2.1981\n",
            "Epoch [85/100], Step [10/50], Loss: 2.2377\n",
            "Epoch [85/100], Step [20/50], Loss: 2.0923\n",
            "Epoch [85/100], Step [30/50], Loss: 2.0856\n",
            "Epoch [85/100], Step [40/50], Loss: 2.1640\n",
            "Epoch [85/100], Step [50/50], Loss: 2.1881\n",
            "Epoch [86/100], Step [10/50], Loss: 2.5795\n",
            "Epoch [86/100], Step [20/50], Loss: 2.8183\n",
            "Epoch [86/100], Step [30/50], Loss: 2.2109\n",
            "Epoch [86/100], Step [40/50], Loss: 2.4765\n",
            "Epoch [86/100], Step [50/50], Loss: 2.3022\n",
            "Epoch [87/100], Step [10/50], Loss: 1.9912\n",
            "Epoch [87/100], Step [20/50], Loss: 2.0239\n",
            "Epoch [87/100], Step [30/50], Loss: 2.1707\n",
            "Epoch [87/100], Step [40/50], Loss: 2.0915\n",
            "Epoch [87/100], Step [50/50], Loss: 1.9944\n",
            "Epoch [88/100], Step [10/50], Loss: 2.0592\n",
            "Epoch [88/100], Step [20/50], Loss: 2.2593\n",
            "Epoch [88/100], Step [30/50], Loss: 2.4595\n",
            "Epoch [88/100], Step [40/50], Loss: 2.2776\n",
            "Epoch [88/100], Step [50/50], Loss: 2.2057\n",
            "Epoch [89/100], Step [10/50], Loss: 1.9502\n",
            "Epoch [89/100], Step [20/50], Loss: 2.1919\n",
            "Epoch [89/100], Step [30/50], Loss: 2.5830\n",
            "Epoch [89/100], Step [40/50], Loss: 1.9887\n",
            "Epoch [89/100], Step [50/50], Loss: 2.1673\n",
            "Epoch [90/100], Step [10/50], Loss: 2.2998\n",
            "Epoch [90/100], Step [20/50], Loss: 2.1150\n",
            "Epoch [90/100], Step [30/50], Loss: 2.5059\n",
            "Epoch [90/100], Step [40/50], Loss: 2.5335\n",
            "Epoch [90/100], Step [50/50], Loss: 2.2670\n",
            "Epoch [91/100], Step [10/50], Loss: 2.3538\n",
            "Epoch [91/100], Step [20/50], Loss: 2.0650\n",
            "Epoch [91/100], Step [30/50], Loss: 2.2126\n",
            "Epoch [91/100], Step [40/50], Loss: 2.0909\n",
            "Epoch [91/100], Step [50/50], Loss: 2.1362\n",
            "Epoch [92/100], Step [10/50], Loss: 2.2124\n",
            "Epoch [92/100], Step [20/50], Loss: 2.1998\n",
            "Epoch [92/100], Step [30/50], Loss: 2.6167\n",
            "Epoch [92/100], Step [40/50], Loss: 2.2584\n",
            "Epoch [92/100], Step [50/50], Loss: 2.0719\n",
            "Epoch [93/100], Step [10/50], Loss: 2.5336\n",
            "Epoch [93/100], Step [20/50], Loss: 1.9028\n",
            "Epoch [93/100], Step [30/50], Loss: 2.0276\n",
            "Epoch [93/100], Step [40/50], Loss: 2.0137\n",
            "Epoch [93/100], Step [50/50], Loss: 2.6012\n",
            "Epoch [94/100], Step [10/50], Loss: 2.2886\n",
            "Epoch [94/100], Step [20/50], Loss: 2.2873\n",
            "Epoch [94/100], Step [30/50], Loss: 2.3480\n",
            "Epoch [94/100], Step [40/50], Loss: 2.3798\n",
            "Epoch [94/100], Step [50/50], Loss: 2.3109\n",
            "Epoch [95/100], Step [10/50], Loss: 2.1455\n",
            "Epoch [95/100], Step [20/50], Loss: 1.8657\n",
            "Epoch [95/100], Step [30/50], Loss: 2.0954\n",
            "Epoch [95/100], Step [40/50], Loss: 1.9995\n",
            "Epoch [95/100], Step [50/50], Loss: 2.4633\n",
            "Epoch [96/100], Step [10/50], Loss: 2.4935\n",
            "Epoch [96/100], Step [20/50], Loss: 2.5831\n",
            "Epoch [96/100], Step [30/50], Loss: 2.1571\n",
            "Epoch [96/100], Step [40/50], Loss: 1.7954\n",
            "Epoch [96/100], Step [50/50], Loss: 2.3501\n",
            "Epoch [97/100], Step [10/50], Loss: 2.6394\n",
            "Epoch [97/100], Step [20/50], Loss: 1.8060\n",
            "Epoch [97/100], Step [30/50], Loss: 2.1285\n",
            "Epoch [97/100], Step [40/50], Loss: 2.9094\n",
            "Epoch [97/100], Step [50/50], Loss: 2.0254\n",
            "Epoch [98/100], Step [10/50], Loss: 2.0074\n",
            "Epoch [98/100], Step [20/50], Loss: 2.3943\n",
            "Epoch [98/100], Step [30/50], Loss: 2.0454\n",
            "Epoch [98/100], Step [40/50], Loss: 2.3612\n",
            "Epoch [98/100], Step [50/50], Loss: 2.3513\n",
            "Epoch [99/100], Step [10/50], Loss: 1.9626\n",
            "Epoch [99/100], Step [20/50], Loss: 1.8997\n",
            "Epoch [99/100], Step [30/50], Loss: 2.1518\n",
            "Epoch [99/100], Step [40/50], Loss: 2.0851\n",
            "Epoch [99/100], Step [50/50], Loss: 2.3881\n",
            "Epoch [100/100], Step [10/50], Loss: 2.3934\n",
            "Epoch [100/100], Step [20/50], Loss: 2.4392\n",
            "Epoch [100/100], Step [30/50], Loss: 2.2864\n",
            "Epoch [100/100], Step [40/50], Loss: 2.2342\n",
            "Epoch [100/100], Step [50/50], Loss: 2.2218\n",
            "Accuracy on test set: 12.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "num_classes = 10\n",
        "num_samples_per_class = 50\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "for i in range(num_classes):\n",
        "    indices = torch.arange(len(train_dataset))[torch.tensor(train_dataset.targets) == i]\n",
        "    train_indices.extend(indices[:num_samples_per_class])\n",
        "    test_indices.extend(indices[num_samples_per_class:num_samples_per_class+5])\n",
        "train_subset = Subset(train_dataset, train_indices)\n",
        "test_subset = Subset(test_dataset, test_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=5, shuffle=False)\n",
        "\n",
        "model = resnet50(pretrained=False, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "for epoch in range(100):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, 100, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy on test set: {:.2f}%'.format(accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), 'modelcl50.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
